# AVA - Afsah's Virtual Assistant
# Core dependencies for local agentic AI on RTX A2000 4GB VRAM
# Production-ready versions with security and compatibility considerations

# ============================================================================
# Core LLM & Optimization Libraries (Critical for 4GB VRAM constraint)
# ============================================================================
transformers>=4.38.0,<5.0.0
torch>=2.1.0  # CUDA support - see docs/INSTALLATION.md for specific installation
torchvision>=0.16.0
torchaudio>=2.1.0

# PEFT & Quantization (Essential for QLoRA and 4-bit optimization)
peft>=0.8.0,<1.0.0
trl>=0.7.0,<1.0.0
bitsandbytes>=0.42.0  # Critical for 4-bit quantization
accelerate>=0.25.0,<1.0.0
datasets>=2.16.0,<3.0.0

# Fast fine-tuning optimization
unsloth>=2024.1.1

# Tokenization and serialization
sentencepiece>=0.1.99,<1.0.0
protobuf>=3.20.0,<5.0.0

# ============================================================================
# Local LLM Management & Serving
# ============================================================================
ollama>=0.1.7,<1.0.0

# ============================================================================
# API Interaction & External Tools
# ============================================================================
openai>=1.12.0,<2.0.0  # For teacher models and API-based tools
requests>=2.31.0,<3.0.0
httpx>=0.27.0,<1.0.0  # Alternative to requests with async support

# ============================================================================
# CLI Development & User Interface
# ============================================================================
typer[all]>=0.9.0,<1.0.0
rich>=13.7.0,<14.0.0  # Enhanced CLI output and formatting
click>=8.1.0,<9.0.0  # Alternative CLI framework (if needed)

# ============================================================================
# Web Server (for custom AVA server beyond Ollama)
# ============================================================================
fastapi>=0.109.0,<1.0.0
uvicorn[standard]>=0.27.0,<1.0.0
pydantic>=2.5.0,<3.0.0  # Data validation and structured output
sse-starlette>=1.8.0,<2.0.0  # Server-sent events for token streaming

# ============================================================================
# Data Handling & Processing
# ============================================================================
pandas>=2.1.0,<3.0.0
numpy>=1.24.0,<2.0.0
PyYAML>=6.0.1,<7.0.0
python-dotenv>=1.0.0,<2.0.0

# ============================================================================
# LlamaIndex Integration (Structured Output & MCP concepts)
# ============================================================================
llama-index>=0.10.0,<1.0.0
llama-index-core>=0.10.0,<1.0.0
llama-index-llms-ollama>=0.1.0,<1.0.0

# ============================================================================
# Async Support & Performance
# ============================================================================
asyncio-throttle>=1.0.2,<2.0.0
aiofiles>=23.2.0,<24.0.0

# ============================================================================
# Security & Authentication (for remote access)
# ============================================================================
passlib[bcrypt]>=1.7.4,<2.0.0
python-jose[cryptography]>=3.3.0,<4.0.0
python-multipart>=0.0.6,<1.0.0

# ============================================================================
# Development & Testing Dependencies
# ============================================================================
pytest>=7.4.0,<8.0.0
pytest-asyncio>=0.23.0,<1.0.0
pytest-cov>=4.1.0,<5.0.0

# Code quality and formatting
ruff>=0.1.15,<1.0.0  # Fast Python linter and formatter
black>=23.12.0,<25.0.0
mypy>=1.8.0,<2.0.0

# ============================================================================
# Optional Dependencies (uncomment as needed)
# ============================================================================
# jupyter>=1.0.0,<2.0.0  # For notebooks
# matplotlib>=3.7.0,<4.0.0  # For visualizations
# seaborn>=0.13.0,<1.0.0  # Enhanced plotting
# scikit-learn>=1.3.0,<2.0.0  # For additional ML utilities

# ============================================================================
# Notes:
# ============================================================================
# 1. CUDA-specific PyTorch installation:
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# 2. bitsandbytes may require OS-specific installation - see docs/INSTALLATION.md
# 3. Tunneling services (localtonet, ngrok) are external services, not Python packages
# 4. Version ranges allow for security updates while maintaining compatibility
# 5. Pin exact versions in production: pip freeze > requirements-lock.txt
